{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import collections as cc\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import re\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir='0819_keyword_analysis.csv'\n",
    "data=pd.read_csv(data_dir,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_desc=data[['id','name','keyword','price','flag_taekpo','flag_used','flag_exchg','description','image_count','name_kor','total_view','purchase_duration']]\n",
    "data_nodesc=data[['id','name','keyword','price','flag_taekpo','flag_used','flag_exchg','image_count','name_kor','total_view','purchase_duration']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_force=data_nodesc[data_nodesc['name_kor']==\"나이키 에어포스 1 '07 로우 화이트\"]\n",
    "air_force=air_force[['id','name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_force.to_csv(\"airforce_only.csv\",index=False,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 한글 영어 번역 -> Fairseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to expression (2588148197.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[34], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    spm_train --input=train.ko --model_prefix=korean --vocab_size=32000 --character_coverage=1.0\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m cannot assign to expression\n"
     ]
    }
   ],
   "source": [
    "spm_train --input=train.ko --model_prefix=korean --vocab_size=32000 --character_coverage=1.0\n",
    "spm_train --input=train.en --model_prefix=english --vocab_size=32000 --character_coverage=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 한글 불용어 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from konlpy.tag import Okt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = air_force['name'].fillna('')\n",
    "keywords=air_force['keyword'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "# 조사와 접속사를 제거한 형태소 리스트 생성\n",
    "stopwords = ['에어포스', '나이키', '에어', '포스', '남성', '우먼', '여성', '제']\n",
    "\n",
    "# 텍스트 데이터를 형태소 분석하여 토큰화\n",
    "def tokenize(text):\n",
    "    tokens = okt.morphs(text, stem=True)  # 형태소 분석 및 어간 추출\n",
    "    tokens = [word for word in tokens if word not in stopwords]  # 불용어 제거\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# 텍스트 데이터에 대해 토큰화 수행\n",
    "tokenized_texts = texts.apply(tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Features: ['신발', '제품', '225', '흰색', '트리플', '스니커즈', '230', '파다', '희다', '오다', '정품', '290', '235', '285', 'mm', '255', '245', '250', '운동화', '240', '260', '상품', '사이즈', '280', '275', '270', '07', '265', '화이트', '로우']\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF 벡터화\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X = vectorizer.fit_transform(tokenized_texts)\n",
    "\n",
    "# 주요 구문 추출\n",
    "features = vectorizer.get_feature_names_out()\n",
    "# TF-IDF 가중치 높은 상위 n개의 구문 추출\n",
    "top_n = 30\n",
    "tfidf_scores = X.toarray().sum(axis=0)\n",
    "top_features = [features[i] for i in tfidf_scores.argsort()[-top_n:]]\n",
    "\n",
    "print(\"Top Features:\", top_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
